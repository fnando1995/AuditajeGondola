{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53fdaff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "\n",
    "hall = \"1\"\n",
    "\n",
    "maestra = pd.read_csv(\"datasets\\evaluacion\\maestra_filtered.csv\"\n",
    "                    ,sep=\",\"\n",
    "                    ,dtype=str)\n",
    "\n",
    "stage1_path     = f\"datasets\\evaluacion\\positional_information\\\\4_pred_stage1_hall_{hall}.json\"\n",
    "stage2_path     = f\"datasets\\evaluacion\\positional_information\\\\4_pred_stage2_hall_{hall}.json\"\n",
    "stage3_path     = f\"datasets\\evaluacion\\positional_information\\\\4_pred_stage3_hall_{hall}.json\"\n",
    "\n",
    "vocabulariopath = \"datasets\\evaluacion\\\\annotations\\\\vocabulario.csv\"\n",
    "\n",
    "df      = pd.read_csv(f\"datasets\\evaluacion\\positional_information\\\\3_eval_cluster_hall_{hall}.csv\"\n",
    "                    ,sep=\",\"\n",
    "                    ,dtype=str)\n",
    "clusterlist = sorted(list(set(df[\"cluster\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4a4ae89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables cotas de lecturas\n",
    "price_conf_thres        = 0.90 # se pueden reducir estos valores\n",
    "description_conf_thres  = 0.75\n",
    "code_conf_thres         = 0.90\n",
    "CODELENGTH              = 9\n",
    "COSINE_DIST_THRESH      = 0.01\n",
    "dictionary_weights = {\"price\":0.70,\"description\":0.25,\"code\":0.05}\n",
    "\n",
    "\n",
    "\n",
    "# confianzas de clusters\n",
    "# price: 0.983256*0.70\n",
    "# description: 0.885963*0.25\n",
    "# code: 0.970569*0.05\n",
    "# total = 0.923569\n",
    "# price: 0.979868\n",
    "# description: 0.905892\n",
    "# code: 0.980545\n",
    "# total=0.935698\n",
    "# price: 0.99999\n",
    "# description: 0.99999\n",
    "# code: 0.0\n",
    "# total=0.95\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7bd38705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtrado de lecturas\n",
    "\n",
    "def validateprice(price,price_conf):\n",
    "    if type(price) is not str:\n",
    "        return \n",
    "    if price_conf<price_conf_thres:\n",
    "        return \n",
    "    if \".\" not in price:\n",
    "        return \n",
    "    entero,decimal=price.split(\".\")\n",
    "    # eliminando posibles textos del boxing por ser rectangular\n",
    "    entero = re.sub('\\D', '', entero)\n",
    "    decimal = re.sub('\\D', '', decimal)\n",
    "    if len(decimal)>2 or len(decimal)<=0:\n",
    "        return \n",
    "    if len(decimal)==1:\n",
    "        # se agrega un cero al final para casos\n",
    "        # observados de que se pierde este numero\n",
    "        # al final.\n",
    "        decimal+=\"0\"\n",
    "    return f\"{entero}.{decimal}\"\n",
    "\n",
    "def validatedescription(description,description_conf):\n",
    "    if type(description) is not str or description_conf<description_conf_thres:\n",
    "        return\n",
    "    # puede que existan valores no alphanumericos por eliminar\n",
    "    return re.sub('\\W+',' ',description)\n",
    "\n",
    "def validatecode(code,code_conf):\n",
    "    if type(code) is not str or not code.isnumeric: \n",
    "        return \n",
    "    elif code_conf<code_conf_thres or len(code)!=CODELENGTH:\n",
    "        return\n",
    "    else:\n",
    "        return code\n",
    "\n",
    "def filtercluster(cluster_data):\n",
    "    new_cluster_data=[]\n",
    "    for data in cluster_data:\n",
    "        # validaciones de precio\n",
    "        price = str(data[0][0]).replace(\" \",\"\").replace(\"$\",\"\")\n",
    "        price_conf = float(data[1][0])\n",
    "        price = validateprice(price,price_conf)\n",
    "        if price is None:\n",
    "            continue\n",
    "        # validaciones descripcion\n",
    "        description = data[0][1]\n",
    "        description_conf = float(data[1][1])\n",
    "        description = validatedescription(description,description_conf)\n",
    "        if description is None:\n",
    "            continue\n",
    "        # cluster original\n",
    "        origcluster=data[2]\n",
    "        # validaciones item extra codigo\n",
    "        code = data[0][2]\n",
    "        code_conf = float(data[1][2])\n",
    "        code = validatecode(code,code_conf)\n",
    "        if code is None:\n",
    "            code_conf = 0\n",
    "        CW = price_conf*dictionary_weights[\"price\"]+\\\n",
    "             description_conf*dictionary_weights[\"description\"]+\\\n",
    "             code_conf*dictionary_weights[\"code\"]\n",
    "        new_cluster_data.append([origcluster,CW,[price,price_conf],[description,description_conf],[code,code_conf]])\n",
    "    return new_cluster_data\n",
    "\n",
    "# funciones para obtener y reinsertar en structura de datos principal\n",
    "def get_descs(struct):\n",
    "    descs=[]\n",
    "    for cluster,data in struct.items():\n",
    "        for origcluster,cw,priceinfo,descinfo,codeinfo in data:\n",
    "            descs.append(descinfo[0])\n",
    "    return descs\n",
    "\n",
    "def insert_desc(struct,descs):\n",
    "    D={}\n",
    "    i=0\n",
    "    for cluster, data in struct.items():\n",
    "        D[cluster]=[]\n",
    "        for origcluster,cw,priceinfo,descinfo,codeinfo in data:\n",
    "            D[cluster].append([origcluster,cw,priceinfo,[descs[i],descinfo[1]],codeinfo])\n",
    "            i+=1\n",
    "    return D\n",
    "\n",
    "# Funciones para obtener similitud\n",
    "def preprocessing(lista_descripciones, stop_words=['DE','EN', 'LA', 'Y', 'POR', 'EL']):\n",
    "    lista_descripciones = [re.sub('[^A-Za-z0-9]+', ' ', s) for s in lista_descripciones]\n",
    "    lista_palabras = [x.split(' ') for x in lista_descripciones]\n",
    "    lista_terminos = [''.join([x.replace(x,'') if x in stop_words else x for x in y]) for y in lista_palabras]\n",
    "    return lista_terminos\n",
    "\n",
    "def cosine_distance(matrix_rows, matriz_cols):\n",
    "    def normalize(matrix):\n",
    "        return np.apply_along_axis(lambda x: x/np.sqrt(x.dot(x)), 1, matrix)\n",
    "    matrix_cos = normalize(matrix_rows).dot(normalize(matriz_cols).transpose())\n",
    "    return np.ones(matrix_cos.shape) - matrix_cos\n",
    "\n",
    "# utils\n",
    "def save_json(data,path):\n",
    "    with open(path,\"w\") as f:\n",
    "        json.dump(data,f,indent=4,sort_keys=True)\n",
    "\n",
    "def get_new_cluster(index):\n",
    "    cluster = str(len(clusterlist)+index).rjust(6,\"0\")\n",
    "    index+=1\n",
    "    return cluster,index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "916065a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creacion de estrucutra principal\n",
    "D = {}\n",
    "for cluster in sorted(clusterlist):\n",
    "    data = df[df[\"cluster\"]==cluster]\n",
    "    data = filtercluster([[list(row[1][[\"price\",\"description\",\"code\"]])\n",
    "                                ,list(row[1][[\"price_conf\",\"description_conf\",\"code_conf\"]])\n",
    "                                ,row[1][\"original_cluster\"]] for row in data.iterrows()])\n",
    "    if len(data)>0:\n",
    "        D[cluster]=data\n",
    "save_json(D,stage1_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "08097fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proyeccion de descripciones a datos de maestra\n",
    "# se puede agregar filtrado por similitud menor a un valor. (Modificaciones en D)\n",
    "# se puede agregar filtrado por validacion de levenstin en code si existe.\n",
    "vocabulario     = [ str(i) for i in list(pd.read_csv(vocabulariopath,dtype=str)['ngramas'])] #lectura nan\n",
    "Mdesc           = list(maestra[\"DESCRIPCION\"])\n",
    "maestradesc     = preprocessing(Mdesc)\n",
    "maestradescvec  = CountVectorizer(ngram_range=(3, 3),analyzer='char',vocabulary=vocabulario).fit_transform(maestradesc).toarray()\n",
    "datadesc        = preprocessing(get_descs(D))\n",
    "datadescvec     = CountVectorizer(ngram_range=(3, 3),analyzer='char',vocabulary=vocabulario).fit_transform(datadesc).toarray()\n",
    "matrix_distance = cosine_distance(datadescvec,maestradescvec)\n",
    "DESCPROYECTED = [ Mdesc[matrix_distance[index].argsort()[0]] for index in range(len(datadesc))]\n",
    "D = insert_desc(D,DESCPROYECTED)\n",
    "save_json(D,stage2_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "63c8a143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separacion de cluster por distancia de coseno\n",
    "ind=0\n",
    "bandera = True\n",
    "repeticiones=0\n",
    "while bandera:\n",
    "    E = D.copy() if repeticiones==0 else F.copy()\n",
    "    F = {}\n",
    "    # print(len(E))\n",
    "    CV  = CountVectorizer(ngram_range=(3, 3),analyzer='char',vocabulary=vocabulario)\n",
    "    for cluster,data in E.items():\n",
    "        if len(data)>1:\n",
    "            listdesc=[ desc for _,_,_,[desc,desc_conf],_ in data]\n",
    "            row = CV.fit_transform(preprocessing(listdesc[:1])).toarray()\n",
    "            cols = CV.fit_transform(preprocessing(listdesc[1:])).toarray()\n",
    "            vector = cosine_distance(row,cols)\n",
    "            valids= np.nonzero(np.array(vector) <= COSINE_DIST_THRESH)[1]+1\n",
    "            valids = np.append(valids, 0)\n",
    "            next_data = [d for i,d in enumerate(data) if i not in valids]\n",
    "            keep_data = [d for i,d in enumerate(data) if i in valids]\n",
    "            if len(keep_data)==1:\n",
    "                E[cluster] = {\"best\":keep_data[0],\"others\":[]}\n",
    "            else:\n",
    "                values=[v for _,v,_,_,_ in keep_data]\n",
    "                best=keep_data.pop(np.array(values).argmax())\n",
    "                E[cluster] = {\"best\":best,\"others\":keep_data}\n",
    "            if len(next_data)>0:\n",
    "                # print(cluster)\n",
    "                c,ind=get_new_cluster(ind)\n",
    "                F[c]=next_data\n",
    "        else:\n",
    "            E[cluster] = {\"best\":data[0],\"others\":[]}\n",
    "    # for c,d in F.items():\n",
    "    #     print(c,[ desc for _,_,_,[desc,desc_conf],_ in d])\n",
    "    if repeticiones==0:\n",
    "        D = E | F\n",
    "    else:\n",
    "        D= D|E|F\n",
    "    if len(F)==0:\n",
    "        bandera=False\n",
    "    repeticiones+=1\n",
    "save_json(D,stage3_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac409762",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ce6886",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
